## 基础
#### 什么是 Redis？

Redis，Remote Dictionary Service，是一个开源的**键值对数据库服务器**，或者说是一个数据结构服务器，它不通过迭代或者排序方式处理数据，而是直接**按照数据结构的方式组织**

主要来说，它是一个**内存数据库**，被用作例如 **MySQL 前的缓存**，来提高应用程序的性能，它利用**内存的高速访问**来减轻核心应用程序数据库的负载，它的 QPS 跟 MySQL 相比也非常高，可以更好地应对**高并发场景**

**不经常更改但经常被请求**的数据，或者**任务关键性较低但经常更改**的数据，都可以存到 Redis 中

![how-is-redis-traditionally-used](how-is-redis-traditionally-used.png)

Redis 对数据的操作都是**原子性**的，它由单线程负责执行命令，**不存在并发竞争的问题**，还支持**事务、持久化、Lua 脚本、多种集群方案（主从复制、哨兵、切片集群）、发布/订阅模式、内存淘汰和过期删除机制**等功能

#### Redis 和 Memcached 有什么区别？

Redis 和 Memcached 都是基于**内存**的数据库，一般都用来当作缓存使用，它们都有过期策略，性能也都非常高

但 Redis **支持的数据类型更加丰富**，还支持**数据的持久化、原生集群和事务**等其他功能，Memcached 是没有持久化功能的，也没有原生的集群模式，更不支持其他功能

#### Redis 是单线程的吗？

Redis 单线程指的是，**接收客户端请求 - 解析请求 - 进行数据读写等操作 - 发送数据给客户端**，这个过程是由一个主线程来完成的，**Redis 程序并不是单线程的**，它在启动时会启动多个**后台线程（BIO）**

![redis-backend-process](redis-backend-process.png)

**关闭文件、AOF 刷盘和释放内存**这三个任务都有各自的任务队列，然后由后台线程去**异步**处理这些任务，从而避免阻塞主线程，提高 Redis 的性能

#### Redis 的单线程模型是什么样的？

Redis 在 6.0 版本之前采用的是单线程模型，所有的客户端请求都是由一个主线程来处理的，通过**I/O 多路复用技术**来同时监听多个客户端连接，当有客户端请求到达时，主线程会依次处理这些请求

![redis-single-process-model](redis-single-process-model.png)

Redis 在初始化时，会先调用 **`epoll_create()`** 和 **`socket()`** 来创建一个 epoll 对象和一个服务端 socket，然后调用 **`bind()`** 和 **`listen()`** 来绑定端口并监听客户端连接请求，再调用 **`epoll_ctl()`** 把服务端监听的 socket 添加到 epoll 对象中，同时注册**连接事件处理函数**

初始化之后，主线程就会进入到一个**事件循环函数**，先调用**处理发送队列函数**，来看发送队列里是否有任务，如果有发送任务，就通过 **`write()`** 函数将**客户端发送缓存区**里的数据发送出去，如果这一轮数据没有发送完，就会注册**写事件处理函数**，等待 **`epool_wait()`** 检测到 socket 可写时，再次调用**处理发送队列函数**来继续发送数据

然后会调用 **`epoll_wait()`** 来等待事件的到来，如果是**连接事件**，就会调用**连接事件处理函数**，它会调用 **`accept()`** 来获取已连接的 socket，然后调用 **`epoll_ctl()`** 把已连接的 socket 添加到 epoll 对象中，同时注册**读事件处理函数**

如果是**读事件**，就会调用**读事件处理函数**，它会调用 **`read()`** 函数来读取客户端发送过来的数据，然后进行命令解析和处理，最后把客户端对象添加到发送队列，将执行结果写到**发送缓存区**等待发送

如果是**写事件**，就会调用**写事件处理函数**，它会调用 **`write()`** 函数来发送客户端发送缓存区里的数据，如果这一轮数据没有发送完，就会继续注册**写事件处理函数**，等待 **`epoll_wait()`** 检测到 socket 可写时，再次调用**写事件处理函数**来继续发送数据

#### 为什么 Redis 采用的是单线程还能这么快？6.0 之前为什么要使用单线程？

单线程的 Redis 吞吐量可以达到 **10w QPS** 以上，主要的原因是 Redis 的大部分操作都在**内存中**完成，并且采用了**高效的数据结构**，**CPU 并不是制约 Redis 性能的瓶颈，机器的内存和网络带宽才是**

Redis 采用的单线程模型**避免了多线程之间的竞争**，节省了**多线程切换**带来的时间和性能上的开销，也避免了**死锁**问题，**I/O 多路复用机制**可以处理大量的客户端 socket 请求，一个线程可以处理多个 IO 流，也就是 **select/epoll** 机制，它**允许内核中存在多个监听 socket 和已连接 socket**，内核会一直监听这些 socket 上的连接请求或数据请求，一旦有请求到达，就会通知 Redis 线程处理，从而实现了**一个 redis 线程处理多个 IO 流的效果**

如果想要使用多核 CPU，可以在一台服务器上启动**多个 Redis 节点或采用分片集群**的方式，并且使用单线程的**可维护性也更高**，多线程模型虽然在某些方面表现优异，但它引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度，同时可能存在线程切换、加锁解锁和死锁造成性能损耗

#### Redis 6.0 之后为什么引入了多线程？

随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在**网络 I/O 的处理**上，所以在 6.0 之后 Redis 也采用了**多个 I/O 线程来处理网络请求**，但对于**命令的执行，Redis 仍然使用单线程来处理**

在默认情况下，Redis 支持的 I/O 多线程特性**只针对发送响应数据**，并不会以多线程的方式处理读请求，要开启多线程处理客户端读请求的话就需要把 **Redis.conf** 配置文件中的 **`io-threads-do-reads`** 选项设置为 **`yes`**，还可以通过 **`io-threads`** 选项来设置 I/O 线程的数量，如果是 4 核的 CPU 建议线程数设置为 2 或 3，8 核则建议设置为 6，线程数一定要小于机器核数，线程数并不是越大越好的

所以在 6.0 版本之后，Redis 启动时在默认情况下，除了主线程以外，会**额外创建 6 个线程**，加起来一共是：

* **Redis-server**
  * **主线程**，主要负责执行命令
* **BIO 线程**，主要负责**异步**处理**后台任务**
  * bin_close_file
    * 关闭文件
  * bin_aof_fsync
    * AOF 刷盘
  * bio_lazy_free
    * 释放内存
* **I/O 线程**，主要负责处理**网络请求**
  * io_thd_1
  * io_thd_2
  * io_thd_3
  * io-threads 默认是 4，所以会启动 4 - 1 = 3 个 I/O 多线程来分担 Redis 网络 I/O 的压力

#### AOF 日志是如何实现的？

Redis 一共有三种数据持久化的方式，分别是 AOF 日志、RDB 快照和混合持久化

**AOF 日志**是指，Redis 在执行完一条写操作命令后，会把该命令以**追加**的方式记录到 AOF 文件中，当 Redis 重启时，会读取 AOF 文件中的命令并逐一执行，从而恢复数据

这样先执行命令再记录的做法可以**避免额外的语法检查开销**，也**不会阻塞当前写操作命令的执行**，但有可能导致数据的丢失和阻塞其他操作，因为 AOF 日志也是在主线程中执行的，会阻塞后续的操作

![aof-write](aof-write.png)

Redis 在执行完写操作命令后，会先将命令追加到 **`server.aof_buf` 缓冲区**，然后通过 `write()` 系统调用将缓冲区的数据写入到 AOF 文件中，此时数据还没有真正落盘，只是在**页缓存**中，要等待内核将数据写入磁盘，Redis 提供了**三种写回磁盘的策略**，可以在 **Redis.conf** 配置文件中通过 **`appendfsync`** 选项来设置，分别是 **Always**，表示每次写操作命令执行完后都会同步将 AOF 日志数据写回磁盘，**Everysec** 表示每隔一秒就将缓冲区里的内容写回磁盘，**No** 则表示不由 Redis 控制，而是让操作系统决定何时写回

![aof-write-back-strategies](aof-write-back-strategies.png)

为了避免 AOF 日志文件**过大**所导致的**性能问题**，Redis 提供了 **AOF 重写机制**，它会**读取同一个键最新的值**，然后在新的 AOF 文件中**只记录最新的键值对**，之前的历史命令就会被丢弃，重写工作完成后再用新的 AOF 文件替换旧的 AOF 文件，从而缩小 AOF 文件的大小，重写的过程是由**后台子进程 `bgrewriteaof`** 来完成的，不会阻塞主进程，主进程仍然可以正常处理命令

使用子进程而不是线程的原因是，多线程之间会共享内存，在**修改共享内存数据**时就需要通过**加锁**来保证数据的安全，导致性能下降，而使用子进程，在创建时父子进程是共享内存数据的，但这个共享的内存**只能以读的方式访问**，当父子进程任意一方修改了该共享内存，就会发生**写时复制**，让父子进程各自有了独立的数据副本，从而避免了加锁带来的性能损耗

为了避免写时复制导致的**数据不一致问题**，Redis 设置了一个 **AOF 重写缓冲区**，在子进程创建之后开始使用，在重写 AOF 期间，当 Redis 执行完一个写命令，它会**同时**把这个写命令写入到 AOF 缓冲区和 AOF 重写缓冲区中，当子进程重写完成后，子进程会向主进程发送一条**信号**（进程间的一种异步通讯方式），主进程收到信号后会调用一个**信号处理函数**，在这个函数中会**将 AOF 重写缓冲区中的所有内容追加的新的 AOF 文件中**，使新旧两个 AOF 文件所保存的数据库状态一致，再将新的 AOF 文件改名，覆盖现有的 AOF 文件，从而完成 AOF 重写操作

#### RDB 快照是如何实现的？

**RDB 快照**记录的是某一个瞬间的**实际内存数据**，在恢复数据时直接将 RDB 文件读入内存就可以，Redis 提供了 **save 和 bgsave** 两个命令来生成 RDB 文件，save 是在**主线程**执行的，所以如果写入 RDB 文件的时间太长，就会阻塞主线程，bgsave 会创建一个**子进程**来生成 RDB 文件，所以可以避免主线程的阻塞

Redis 的快照是**全量快照**，每次执行都会把内存中的**所有**数据都记录到磁盘中，在执行 bgsave 过程中，基于**写时复制**技术，Redis 可以继续处理操作命令，数据是能被修改的，被修改的数据会复制一份副本，由 bgsave 子进程把该副本数据写入 RDB 文件

![copy-on-write](copy-on-write.png)

#### 为什么会有混合持久化？

混合持久化集成了 AOF 日志和 RDB 快照的优点，混合使用它们，它工作在 AOF 日志的重写过程，fork 出来的重写**子进程**会先将与主进程共享的内存数据**以 RDB 方式写入 AOF 文件**，主线程处理的操作命令会被记录到 AOF 重写缓冲区中，里面的增量命令会以 AOF 方式写入到 AOF 文件，所以如果使用了混合持久化，AOF 文件的**前半部分**就是 RDB 格式的全量数据，**后半部分**是 AOF 格式的增量数据

这样加载时速度会很快，数据丢失风险也会降低，但会导致 AOF 文件的可读性变得很差

#### Redis 是如何实现服务高可用的？

Redis 通过多个服务节点的主从复制、哨兵和切片集群来保证服务的高可用

**主从复制：**

主从复制是 Redis 高可用服务最基础的保证，将一台 Redis 服务器的数据同步到多台 Redis 服务器上，也就是**一主多从**的模式，主从服务器之间采用**读写分离**，主节点可以进行读写操作，当发生写操作时会自动将写操作同步给从节点，从节点一般是只读

![master-slave](master-slave.png)

所有的数据修改都只在主节点上进行，主从节点之间的命令复制**异步**进行，主节点自己在本地执行完命令后，不会等待从节点的响应就直接返回给客户端，这样可以提高主节点的性能，但也会带来**数据不一致的问题**，也就是无法实现强一致性保证

**哨兵模式：**

当主从节点出现故障宕机时，**哨兵节点**可以**监控主从节点的状态**，当发现主节点宕机时，会自动将某个从节点升级为新的主节点，并通知其他从节点切换到新的主节点，从而保证 Redis 服务的高可用，也就是提供**主从节点故障转移**的功能

![redis-sentinel](redis-sentinel.png)

**切片集群：**

切片集群方案将数据分布在不同的服务器上，以此**降低系统对单一主节点的依赖**，它采用**哈希槽**的方式来处理数据和节点之间的映射关系，一个切片集群共有 16384 个哈希槽，这些哈希槽类似**数据分区**，每个键值对会根据它的 key 被映射到一个对应的哈希槽中

映射的过程主要是通过 CRC16 算法来计算 key 的一个 16 bit 的哈希值，然后用这个 16 位的哈希值对 16384 取模，得到的结果就是该 key 对应的哈希槽编号

在使用 **cluster create** 命令创建集群时，Redis 会自动把所有哈希槽平均分布到集群节点上，或者也可以通过 **cluster meet 和 cluster addslots** 命令手动分配哈希槽，前者是手动建立节点之间的连接，后者是手动分配每个节点上的哈希槽数量，但在手动分配哈希槽时需要把 16384 个哈希槽全部分配完，否则集群无法正常工作

#### 集群脑裂导致数据丢失是什么？该怎么解决？

如果在一主多从的部署方式下，**主节点和从节点之间的网络出现故障**，导致主节点与所有的从节点都失联了，但主节点与客户端的网络还是正常的，客户端也不知道 Redis 内部已经出现了网络故障，所以它仍然会**继续**向主节点发送写操作命令，主节点也会继续执行这些写操作命令，并返回给客户端成功的响应，但因为主从节点之间的网络问题，主节点**无法**将这些写操作命令**同步**给从节点

此时哨兵也发现主节点失联，那它会认为主节点**挂了**，于是在从节点之间选举一个 leader 作为新的主节点，这样就有了**两个主节点**，如果后续网络恢复，**哨兵就会把原本的主节点降级为从节点**，它会先**清空本地的所有数据**，再向新的主节点做**全量同步**，这样之前客户端写入的数据就丢失了，也就是**集群脑裂的情况下丢失数据**

在 Redis 的配置文件中有 **`min-slaves-to-write` 和 `min-slaves-max-lag`** 这两个参数，前者表示**主节点必须要有多少个从节点连接**，后者表示**主从数据的复制和同步不能超过多少秒**，如果这两个有一个不能满足，那**向主节点写入数据的请求就会被拒绝**，也就是通过**限制原本的主节点的写入操作**，来避免脑裂情况下的数据丢失问题，但这也会带来主节点不可用的问题，所以需要根据实际业务场景来权衡选择

#### Redis 使用的过期删除策略是什么？

每当我们对一个 key 设置了过期时间后，Redis 会在内部维护一个**过期字典**，用来存储所有设置了过期时间的 key 和它们对应的过期时间，Redis 使用的过期删除策略是惰性删除和定期删除的配合使用

**惰性删除**指的是 Redis **不会主动删除过期键**，而是每次从数据库访问 key 时都检测它是否过期，如果过期了就删除它并返回空值给客户端，如果没有过期就正常返回对应的值，它会消耗很少的系统资源，但可能导致内存空间的浪费

![lazy-deletion](lazy-deletion.png)

**定期删除**指的是每隔一段时间就随机从数据库中取出一定数量的 key 进行检查，删除其中的过期 key，如果在检查过程中发现过期 key 的比例超过一定的阈值，就会继续进行下一轮检查，直到过期 key 的比例**低于**该阈值为止，这样通过限制操作执行的时长和频率，减少了删除操作对 CPU 的影响，减少内存空间的浪费，但难以确定删除操作执行的时长和频率

![scheduled-deletion](scheduled-deletion.png)

#### Redis 持久化时会如何处理过期键？

